<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE rfc SYSTEM "rfc2629.dtd" [

<!ENTITY RFC7323 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.7323.xml">
<!ENTITY RFC3819 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.3819.xml">
<!ENTITY RFC6555 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.6555.xml">
<!ENTITY RFC6824 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.6824.xml">
<!ENTITY RFC7413 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.7413.xml">
<!ENTITY RFC7540 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.7540.xml">
<!ENTITY RFC7665 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.7665.xml">
<!ENTITY I-D.boucadair-mptcp-plain-mode SYSTEM "http://xml.resource.org/public/rfc/bibxml3/reference.I-D.boucadair-mptcp-plain-mode.xml">
<!ENTITY I-D.dunbar-e2e-latency-arch-view-and-gaps SYSTEM "http://xml.resource.org/public/rfc/bibxml3/reference.I-D.dunbar-e2e-latency-arch-view-and-gaps.xml">
<!ENTITY I-D.ietf-sfc-nsh SYSTEM "http://xml.resource.org/public/rfc/bibxml3/reference.I-D.ietf-sfc-nsh.xml">
<!ENTITY I-D.ietf-tls-tls13 SYSTEM "http://xml.resource.org/public/rfc/bibxml3/reference.I-D.ietf-tls-tls13.xml">
<!ENTITY I-D.ietf-quic-transport SYSTEM "http://xml.resource.org/public/rfc/bibxml3/reference.I-D.ietf-quic-transport.xml">
<!ENTITY I-D.nrooney-marnew-report SYSTEM "http://xml.resource.org/public/rfc/bibxml3/reference.I-D.nrooney-marnew-report.xml">
]>

<?xml-stylesheet type='text/xsl' href='rfc2629.xslt' ?>
<?rfc strict="yes" ?>
<?rfc toc="yes"?>
<?rfc tocdepth="4"?>
<?rfc symrefs="yes"?>
<?rfc sortrefs="yes" ?>
<?rfc compact="yes" ?>
<?rfc subcompact="no" ?>
<rfc category="info" docName="draft-arkko-arch-low-latency" ipr="trust200902">

  <front>

    <title abbrev="Low Latency">Low Latency Applications and the Internet Architecture</title>

    <author fullname="Jari Arkko" initials="J." 
            surname="Arkko">
      <organization>Ericsson</organization>

      <address>
        <postal>
          <street></street>

          <city>Kauniainen</city>

          <region></region>

          <code>02700</code>

          <country>Finland</country>
        </postal>

        <email>jari.arkko@piuha.net</email>

      </address>
    </author>
    
    <author fullname="Jeff Tantsura" initials="J." surname="Tantsura">
      <organization>Futurewei, Future Networks</organization>
      <address>
        <email>jefftant.ietf@gmail.com</email>
      </address>
    </author>
    
    <date month="July" year="2017" />

    <area>Internet</area>

    <workgroup>Internet Engineering Task Force</workgroup>

    <abstract>

      <t>Some recent Internet technology developments relate to
      improvements in communications latency. For instance,
      improvements in radio communications or the recent work in IETF
      transport, security, and web protocols. There are also potential
      applications where latency would play a more significant
      role than it has traditionally been in the Internet
      communications. Modern networking systems offer many tools for
      building low-latency networks, from highly optimised individual
      protocol components to software controlled, virtualised and
      tailored network functions. This memo views the developments
      from a system viewpoint, and considers the potential future
      stresses that the strive for low-latency support for
      applications may bring.</t>

    </abstract>
  </front>

  <middle>

    <section title="Introduction">

      <t>Some recent Internet technology developments relate to
      improvements in communications latency. For instance,
      improvements in radio communications or the recent work in IETF
      transport, security, and web protocols.</t>

      <t>There are also potential applications where latency would play
      a more significant role than it has traditionally
      been in the Internet communications.</t>

      <t>New applications or technologies do not necessarily imply
      that latency should be the main driving concern, or that any
      further efforts are needed, beyond those already ongoing. Indeed,
      modern networking systems offer many tools for building
      low-latency networks, across the stack. At the IETF, for
      instance, there has been a recent increase in work related to
      transport, security, and web application protocols, in part to
      make significant improvements in latency and connection set-up
      times. Similar efforts for other components of communications
      technology exist in
      3GPP, IEEE, and other standards organisations.</t>

      <t>Despite a large number of specific developments, it may be
      interesting to view the developments from a system viewpoint,
      and to consider the potential future stresses that the strive
      for low-latency support applications may bring.</t>

      <t>The rest of this memo is organised as follows: <xref
      target="applications"/> discusses potential applications for
      low-latency communications. <xref target="review"/> reviews some
      of the recent work across the stack, related to latency
      improvements. Finally, <xref target="architecture"/> discusses
      some of the implications (and non-implications) from an
      architectural perspective.</t>

    </section>

    <section anchor="applications" title="Applications with Special Focus on Low Latency">

      <t>Most Internet applications enjoy significant benefits from
      low-latency communications in the form of faster setup and response times
      as well as higher bandwidth communications enabled by transport protocol
      behaviour <xref target="RFC7323"/>.</t>

      <t>There are also potential applications where latency would play
      an even more significant role. For instance,
      embedding communications technology in automation or traffic
      systems, or consumer applications such as augmented or virtual
      reality where due to the human brain's perceptual limits variability in latency	
      may not be feasible, i.e., render
      the service unusable due to motion sickness caused.</t>

      <t>Many of the Internet-of-Things and critical services use
      cases in 5G, for instance, have been listed as requiring low
      latency and high reliability for communications <xref
      target="ER2015"/> <xref target="HU2015"/> <xref
      target="NGMN2015"/> <xref target="NO2015"/> <xref
      target="QU2016"/> <xref target="IMT2020"/>.</t>

      <t>Some example use cases include optimisation of utility
      services such as electricity networks, connected automation
      systems in factories, remote control of machinery such as mining
      equipment, or embedded technology in road or railway
      traffic.</t>

      <t>The different applications vary in terms of their needs.
      Some may be very focused on high-speed local area communication,
      others need to connect at optimal speed over a wide-area
      network, and yet others need to find the right ways to provide
      global services without incurring unreasonable
      delays.</t>

      <t>For these reasons it is difficult to specify what "low latency"
      means in terms of specific delays. Applications and network
      scenarios differ. Reaching a 50ms latency may be enough for
      some applications while others may require 50us. Obviously,
      latency is ultimately limited by physics, location,
      and topology. Individual link characteristics are important,
      but system level communication needs both in terms of
      what is being communicated and between what parties matter
      more.</t>
	    
      <t>Note that when we say "low-latency capabilities", there is no
      intent to imply any specific implementation of those
      capabilities.  In particular, we look at the low-latency
      requirements from a broader perspective than Quality-of-Service
      guarantees or separating traffic onto different classes. Indeed,
      while today's virtualisation and software-driven technologies
      give us more tools to deal with those kinds of arrangements as
      well, past experience on deploying Quality-of-Service mechanisms
      in the Internet should give us a pause <xref
      target="CC2015"/>.</t>

      <t>It is not the purpose of this memo to analyse the application
      requirements for low-latency applications much further; for our
      purposes it suffices to note that there are applications that
      are enabled by low-latency capabilities of the underlying
      network infrastructure.</t>
      
    </section>

    <section title="Role of Low-Latency vs. Other Communications">

      <t>There are some limited applications that rely solely on local
      communication. One example of such an application is vehicles
      communicating braking status to nearby ones.</t>
	    
      <t>Also, while many applications run in the global Internet,
      some are designed for specialised networks that may not have
      full or even any Internet connectivity, but yet use
      IP technology.</t>
		    
      <t>However, many
      applications will include also wide-area communication. If the
      factory automation machines are not talking other than with
      themselves, at least their control systems are doing so in order
      to ensure parts orders, monitoring and maintenance by equipment
      manufacturers, and so on. This does not imply that these perhaps
      critical applications are openly accessible from the Internet,
      but many of them are likely to communicate outside their
      immediate surroundings.</t>
      
      <t>Many applications also rely on wide-area connectivity for
      software updates.</t>

      <t>As a result, this document recommends that when building
      architectures for low-latency applications it is important to
      take into account that these applications can also benefit from
      communications elsewhere. Or at the very least, the existence
      of a specialised communications link or network should not be
      immediately taken to mean that no other communications
      are needed.</t>
      
    </section>
    
    <section anchor="review" title="Selected Improvements to Communications Latency">

      <t>It should be noted that latency is a very broad topic in
      communications protocol design, almost as broad as "security", or
      even "correctness".</t>

      <t>Implementation techniques to satisfy these requirements vary,
      some applications can be built with sufficient fast local
      networking capabilities, others may require, for instance,
      building world-wide, distributed content delivery
      mechanisms.</t>
      
      <t>Modern networking systems offer many tools for building
      low-latency networks, across the stack. from highly optimised
      individual protocol components <xref
      target="I-D.ietf-tls-tls13"/> <xref
      target="I-D.ietf-quic-transport"/> <xref target="RFC7413"/>
      <xref target="RFC7540"/> to
      software controlled, virtualised and tailored network functions
      <xref target="NFV2012"/> <xref target="RFC7665"/> <xref target="I-D.ietf-sfc-nsh"/> <xref
      target="OF2008"/>. Data- and software-driven network management
      and orchestration tools enable networks to be built to serve
      particular needs as well as to optimize workload	
      placement in a way low-latency requirements could be met.</t>

      <t>Across the stack there are also many other
      tools, as well as tools being in development, e.g., a new
      transport design <xref target="L4S"/> at the IETF.</t>

      <t>On
      the lower layers, improvements in radio communications are being
      made. For instance, the IEEE 802.1 Time-Sensitive Networking
      Task Group <xref target="TSN8021"/> has worked to define precise
      time synchronization mechanisms for a local area network, and
      scheduling mechanisms to enable different classes of traffic to
      use the same network while minimising jitter and latency. At the
      IETF, the DETNET working group is taking these capabilities and
      applying them for layer 3 networking <xref
      target="DETNET"/>.</t>

      <t>The 3GPP 5G requirements for next-generation access
      technology are stringent, and are leading to the optimization of
      the radio interfaces. The requirements specify a one-way latency
      limit of 0.5ms for ultra-reliable low-latency communications
      <xref target="TS38913"/>. But again, mere latency numbers mean
      very little without the context of a system and what an
      application needs to communicate and with whom.</t>

    </section>

    <section anchor="architecture" title="Architectural Considerations">

      <t>Despite a large number of specific developments, it may be
      interesting to view the developments from a system viewpoint,
      and to consider the potential future stresses that the strive
      for low-latency support for applications may bring.</t>

      <section title="Background">

	<t>To begin with, it may be useful to observe that the
	requirements and developments outlined above do not necessarily
	imply that any specific new technology is needed or that the
	nature of communications in the Internet would somehow
	fundamentally change. And certainly not that latency should be
	the only or primary concern in technology development.</t>
	
	<t>With the drive for a new class of applications, there is
	often an expectation that this means significant
	changes. However, all changes need to stand on their own, be
	justifiable and deployable on a global network. For instance,
	the discussion around the introduction of the newest 4K or 8K
	high-definition video streaming applications is reminiscent of
	the discussions about the introduction of VoIP applications in
	the Internet. At the time, there was some expectation that
	special arrangements and Quality-of-Service mechanisms might be
	needed to support this new traffic class. This turned out to be
	not true, at least not in general networks.</t>

	<t>Experience tells us, for instance, that deploying
	Quality-of-Service mechanisms in the Internet is hard, not so
	much because of the technology itself, but due to lack of
	forces that would be able to drive the necessary business
	changes in the ecosystem for the technology to be feasibly
	deployable <xref target="CC2015"/>. As claffy and Clark note:

	<list style="empty">
	  
	  <t>"Although the Internet has a standards body (the IETF) to
	  resolve technical issues, it lacks any similar forum to
	  discuss business issues such as how to allocate revenues
	  among competing ISPs offering enhanced services.  In the
	  U.S., ISPs feared such discussions would risk anti-trust
	  scrutiny. Thus, lacking a way to negotiate the business
	  implications of QoS, it was considered a cost rather than a
	  potential source of revenue. Yet, the relentless growth of a
	  diversity of applications with widely varying performance
	  requirements continued on the public Internet, with ISPs
	  using relatively primitive, and not always completely
	  benign, mechanisms for handling them."</t>
	  
	</list></t>
	
	<t>These difficulties should not be read as prohibiting all
	changes. Of course, change can also seem unlikely even in
	cases where it becomes absolutely necessary or the forces
	necessary to make a change have actually built up. As a result,
	statements regarding change in the Internet should be
	carefully evaluated on their merits from both technical and
	ecosystem perspective.</t>
	
	<t>Secondly, we often consider characteristics from a too narrow
	viewpoint. In the case of latency, it is easy to focus on a particular
	protocol or link, whereas from the user perspective latency is
	a property of the system, not a property of an individual component.</t>
	
	<t>For instance, improvements on the performance of one link
	on a communications path can be insignificant, if the other
	parts make up a significant fraction of the system-level
	latency.  That may seem obvious, but many applications are
	highly dependent on communications between a number of
	different parties which may reside in different places. For
	instance, a third party may perform authentication for a
	cloud-based service that also interacts with user's devices
	and a number of different sensors and actuators.</t>

	<t>We cannot change
	the speed of light, and a single exchange with another part of
	the world may result in a 100ms delay, or about 200 times longer
	than the expected 5G radio link delay for critical
	applications. It is clear that designing applications from a
	system perspective is very important.</t>
	
      </section>

      <section title="Implications">

	<t>This section discusses a selected set of architectural effects and
	design choices within applications that desire low latency communications.</t>
		
	<section title="Service Distribution">
		
	<t>As noted above, low-latency applications need to pay
	particular attention to the placement of services in the
	global network. Operations that are on the critical path for
	the low-latency aspects of an application are unlikely to work
	well if those communications need to traverse half of the
	Internet.</t>

	<t>Many widely used services are already distributed and
	replicated throughout the world, to minimise communications
	latency. But many other services are not distributed in this
	manner. For low-latency applications such distribution becomes
	necessary. Hosting a global service in one location is not
	feasible due to latency, even when from a scale perspective a
	single server might otherwise suffice for the service.
	All major public cloud providers offer CDN services	
 	to their customers - AWS's CloudFront, Google's Cloud CDN and	
 	Azure's CDN to mention a few.</t>

        <t>Content-Delivery Networks (CDNs) and similar arrangements
        are likely to flourish because of this.  These arrangements
	can bring content close to end-users, and have a significant
	impact on latency. Typical CDN arrangements provide services
	that are on a global scale nearby, e.g., in the same country
	or even at the ISP's datacenter.</t>
	
	<t>Today's CDNs are of course just one form of distributed
	service implementation. Previous generations, such as web
	caching, have existed as well, and it is likely that the
	current arrangements will evolve in the future. CDN evolution
	is also naturally affected not only by the need to provide
	services closer to the user, but also through the fine-grained
	control and visibility mechanisms that it gives to the
	content owners. Such factors continue to affect also future
	evolution, e.g., any information-centric networking 
	solutions that might emerge.</t>
		
        </section>
	      
	<section title="Edge Computing">
			
        <t>Recent advances in "edge computing" take the more traditional
	type service like CDN as well as a new class of services that require
	"local compute" capabilities placement even further by providing services near
	the users. This would enable more extreme uses cases
	where latency
	from, say, ISP datacenter to the users is considered
	too high. An important consideration is what is considered
	an edge, however. From Internet perspective edge usually
	refers to the IP point of presence or the first IP hop.
	But given the centralised nature of many access networks,
	some of the discussions around the use of edge computing
	also involve components at the edge that are much closer to
	user than the first IP hop. Special arrangements are
	needed to enable direct IP connectivity from the user
	equipment to these components.</t>
	
	</section>
	    
	<section title="Routing and tunnels">
		
	<t>How the communications are routed also matters.  For
	instance, architectures based on tunneling to a central point
	may incur extra delay. One way to address this pressure is to use SDN- and
	virtualisation-based networks that can be provisioned in the
	desired manner, so that, for instance, instances of tunnel
	servers can be placed in the topologically optimal place for a
	particular application.</t>
		
        </section>

	<section title="Alternative Paths and Control Tension">
		
	<t>Recent developments in multipath transport protocols <xref
	target="RFC6824"/> also provide application- and service-level
	control of some of the networking behaviour. Similar choices
	among alternative paths also exist in simpler techniques,
	ranging from server selection algorithms to IPv6 "Happy Eyeballs"
	algorithms <xref target="RFC6555"/>. In all of these cases
	an application makes some observations of the environment
	and decides to use an alternative path or target that
	is perceived to be best suited for the application's needs.</t>
		
	<t>In all of these multipath and alternative selection
	techniques there is tension
	between application control (often by content providers)
	and network control (often by network operators).</t>

	<t>One special case where that tension has appeared in the
	past is whether there should be ways to provide information
	from applications to networks on how packets should be
	treated.  This was extensively discussed during the discussion
	stemming from implications of increased use of encryption in
	the Internet, and how that affects operators <xref
	target="I-D.nrooney-marnew-report"/>.</t>
	
	<t>Another case where there is tension is between mechanisms
	designed for a single link or network vs. end-to-end
	mechanisms. Many of the stated requirements for low-latency
	applications are explicitly about end-to-end characteristics
	and capabilities. Yet, the two mechanisms are very different,
	and most of the deployment difficulties reported in <xref
	target="CC2015"/> relate to end-to-end mechanisms.</t>

	<t>Note that some of the multipath techniques can be used
	either by endpoints or by the network. Proxy-based Multipath TCP
	is one example of this <xref target="I-D.boucadair-mptcp-plain-mode"/>.</t>
	      
	</section>
	    
	<section title="Cross-Layer Optimisations">
		
	<t>In the search for even faster connection setup
	times one obvious technique is cross-layer optimisation.  We
	have seen some of this in the IETF in the rethinking of the
	layers for transport, transport layer security, and
	application framework protocols. By taking into account
	the protocol layer interactions or even bundling the
	protocol design together, it is relatively easy to
	optimise the connection setup time, as evidenced
	by recent efforts to look for "0-RTT" designs in various
	protocols.</t>

	<t>But while cross-layer optimisation can bring benefits, it
	also has downsides. In particular, it connects different parts
	of the stack in additional ways. This can lead to difficulties in
	further evolution of the technology, if done wrong.

	<list style="empty">

	  <t>In the case of the IETF transport protocol evolution,
	  significant improvements were made to ensure better
	  evolvability of the protocols than what we've experienced
	  with TCP, starting from an ability to implement the new
	  protocols in applications rather than in the kernel.</t>

	</list></t>

	<t>While the connection setup is an obvious example, cross-layer
	optimisations are not limited to them. Interfaces between
	application, transport, networking, and link layers can
	provide information and set parameters that improve
	latency. For instance, setting DSCP values or requesting
	a specialised L2 service for a particular application.
	Cross-Layer optimisations between lower	
 	layers will be discussed in the upcoming versions of the draft.</t>
		
	<t>The effects of badly designed cross-layer optimisation are
	a particular form of Internet ossification. The general
	networking trend, however, is for greater flexibility and
	programmability.  Arguably, the ease at which networks can
	evolve is probably even more important than their specific
	characteristics.</t>

	<t>These comments about cross-layer optimisation should
	not be interpreted to mean that protocol design should not
	take into account how other layers behave. The IETF has
	a long tradition of discussing link layer design implications
	for Internet communications (see, e.g., the results of the
	PILC working group <xref target="RFC3819"/>.</t>
		
	</section>
	      
    </section>

      <section title="Recommendations for Further Work">

	<t>Low-latency applications continue to be a hot topic in
	networking. The following topics in particular deserve further
	work from an architectural point of view:

	<list style="symbols">

	  <t>Application architectures for globally connected but
	  low-latency services.</t>

	  <t>What are the issues with inter-domain Quality-of-Service
	  mechanisms? Are there approaches that would offer progress
	  on this field?</t>

	  <t>Network architectures that employ tunneling, and
	  mitigations against the delay impacts of tunnels (such as
	  tunnel server placement or "local breakout" techniques).
          Low latency often implies high reliability, special care is	
 	  to be taken of network convergence, and other, relevant	
 	  characteristics of the underlying infrastructure.</t>

	  <t>The emergence of cross-layer optimisations and how that
	  affects the Internet architecture and its future
	  evolution.</t>

	  <t>Inter-organisatorial matters, e.g., to what extent
	  different standards organisations need to talk about low
	  latency effects and ongoing work, to promote system-level
	  understanding?</t>
	  
	</list></t>

	<t>Overall, this memo stresses the importance of the
	system-level understanding of Internet applications and their
	latency issues. Efforts to address specific sub-issues are
	unlikely to be fruitful without a holistic plan.</t>

        <t>In the authors' opinion, the most extreme use cases (e.g.,
        1ms or smaller latencies) are not worth building
        general-purpose networks for. But having the necessary tools
        so that networks can be flexible for the more general cases is
        very useful, as there are many applications that can benefit
        from the added flexibility. The key tools for this include
        ability to manage network function placement and topology.</t>

      </section>

    </section>

    <section anchor="ack" title="Acknowledgements">

      <t>The author would like to thank Brian Trammell, Mirja
      Kuehlewind, Linda Dunbar, Goran Rune, Ari Keranen, James Kempf, Stephen Farrell,
      Mohamed Boucadair, Kumar Balachandran, Goran AP Eriksson,
      and many
      others for interesting
      discussions in this problem space.</t>

      <t>The author would also like to acknowledge the important
      contribution that <xref
      target="I-D.dunbar-e2e-latency-arch-view-and-gaps"/> made in
      this topic.</t>

    </section>

  </middle>

  <back>

    <references title="Informative References">

      &RFC7323;
      &RFC3819;
      &RFC6555;
      &RFC6824;
      &RFC7413;
      &RFC7540;
      &RFC7665;
      &I-D.ietf-sfc-nsh;
      &I-D.ietf-tls-tls13;
      &I-D.ietf-quic-transport;
      &I-D.boucadair-mptcp-plain-mode;
      &I-D.dunbar-e2e-latency-arch-view-and-gaps;
      &I-D.nrooney-marnew-report;

      <reference anchor="CC2015">
        <front>
          <title>Adding Enhanced Services to the Internet: Lessons from History</title>
          <author initials="kc" surname="claffy"></author>
          <author initials="D." surname="Clark"></author>
<date month='September' year='2015 (https://www.caida.org/publications/papers/2015/adding_enhanced_services_internet/adding_enhanced_services_internet.pdf)'/>
        </front>
        <format type='PDF'
		target='https://www.caida.org/publications/papers/2015/adding_enhanced_services_internet/adding_enhanced_services_internet.pdf'/>
      </reference>

      <reference anchor="OF2008">
        <front>
          <title>OpenFlow: Enabling Innovation in Campus Networks</title>
          <author initials="N." surname="McKeown"></author>
          <author initials="T." surname="Anderson"></author>
          <author initials="H." surname="Balakrishnan"></author>
          <author initials="G." surname="Parulkar"></author>
          <author initials="L." surname="Peterson"></author>
          <author initials="J." surname="Rexford"></author>
          <author initials="S." surname="Shenker"></author>
          <author initials="J." surname="Turner"></author>
          <date month='ACM SIGCOMM Computer Communication Review, Volume 38, Issue 2, pp. 69-74' year='2008'/>
        </front>
      </reference>

      <reference anchor="ER2015">
        <front>
          <title>5G Radio Access for Ultra-Reliable and Low-Latency Communications</title>
          <author initials="O." surname="Yilmaz"></author>
	  <date month='Ericsson Research Blog, May' year='2015 (https://www.ericsson.com/research-blog/5g/5g-radio-access-for-ultra-reliable-and-low-latency-communications/)'/>
	</front>
	<format type='HTML'
		target='https://www.ericsson.com/research-blog/5g/5g-radio-access-for-ultra-reliable-and-low-latency-communications/'/>
      </reference>

      <reference anchor="HU2015">
        <front>
          <title>5G Vision: 100 Billion connections, 1 ms Latency, and 10 Gbps Throughput</title>
          <author fullname="Huawei"></author>
	  <date month='Huawei' year='2015 (http://www.huawei.com/minisite/5g/en/defining-5g.html)'/>
	</front>
	<format type='HTML'
		target='http://www.huawei.com/minisite/5g/en/defining-5g.html'/>
      </reference>

      <reference anchor="QU2016">
        <front>
          <title>Leading the world to 5G</title>
          <author fullname="Qualcomm Technologies, Inc."></author>
	  <date month='Qualcomm, February' year='2016 (https://www.qualcomm.com/media/documents/files/qualcomm-5g-vision-presentation.pdf)'/>
	</front>
	<format type='PDF'
		target='https://www.qualcomm.com/media/documents/files/qualcomm-5g-vision-presentation.pdf'/>
      </reference>

      <reference anchor="NGMN2015">
        <front>
          <title>5G White Paper</title>
          <author fullname="NGMN Alliance"></author>
	  <date month='NGMN Alliance, February' year='2015 (https://www.ngmn.org/fileadmin/ngmn/content/downloads/Technical/2015/NGMN_5G_White_Paper_V1_0.pdf)'/>
	</front>
	<format type='HTML'
		target='https://www.ngmn.org/fileadmin/ngmn/content/downloads/Technical/2015/NGMN_5G_White_Paper_V1_0.pdf'/>
      </reference>

      <reference anchor="NO2015">
        <front>
          <title>5G the next major wireless standard</title>
          <author initials="K." surname="Doppler"></author>
	  <date month='DREAMS Seminar, January' year='2015 (https://chess.eecs.berkeley.edu/pubs/1084/doppler-DREAMS_5G_jan15.pdf)'/>
	</front>
	<format type='HTML'
		target='https://chess.eecs.berkeley.edu/pubs/1084/doppler-DREAMS_5G_jan15.pdf'/>
      </reference>

      <reference anchor="NFV2012">
        <front>
          <title>Network Functions Virtualisation - Introductory White Paper</title>
          <author fullname="ETSI"></author>
          <date month='ETSI, http://portal.etsi.org/NFV/NFV_White_Paper.pdf, October' year='2012'/>
        </front>
        <format type='PDF'
		target='http://portal.etsi.org/NFV/NFV_White_Paper.pdf'/>
      </reference>

      <reference anchor="IMT2020">
        <front>
          <title>Framework and overall objectives of the future development of IMT for 2020 and beyond</title>
          <author fullname="ITU"></author>
	  <date month='ITU Recommendation M.2083-0, September' year='2015 (http://www.itu.int/rec/R-REC-M.2083-0-201509-I/en)'/>
	</front>
	<format type='HTML'
		target='http://www.itu.int/rec/R-REC-M.2083-0-201509-I/en'/>
      </reference>

      <reference anchor="TS38913">
        <front>
          <title>3rd Generation Partnership Project;
          Technical Specification Group Radio Access Network;
          Study on Scenarios and Requirements for
          Next Generation Access Technologies;
          (Release 14)</title>
          <author fullname="3GPP"></author>
	  <date month='3GPP Technical Report TR 38.913 V14.2.0, March' year='2017 (https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=2996)'/>
	</front>
	<format type='HTML'
		target='https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=2996'/>
      </reference>

      <reference anchor="TSN8021">
        <front>
          <title>Time-Sensitive Networking Task Group</title>
          <author fullname="IEEE"></author>
	  <date month='' year='IEEE (http://www.ieee802.org/1/pages/tsn.html)'/>
	</front>
	<format type='HTML'
		target='http://www.ieee802.org/1/pages/tsn.html'/>
      </reference>

      <reference anchor="DETNET">
        <front>
          <title>Deterministic Networking (DETNET) Working Group</title>
          <author fullname="IETF"></author>
	  <date month='March' year='2016 (https://tools.ietf.org/wg/detnet/charters)'/>
	</front>
	<format type='HTML'
		target='https://tools.ietf.org/wg/detnet/charters'/>
      </reference>

      <reference anchor="L4S">
        <front>
          <title>Low Latency Low Loss Scalable throughput (L4S) Birds-of-Feather Session</title>
          <author fullname="IETF"></author>
	  <date month='July' year='2016 (https://datatracker.ietf.org/wg/l4s/charter/)'/>
	</front>
	<format type='HTML'
		target='https://datatracker.ietf.org/wg/l4s/charter/'/>
      </reference>

    </references>

  </back>
</rfc>
